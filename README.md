# Optimistic Verifiable Training by Controlling Hardware Nondeterminism

Under construction!


This repository contains the code for the paper [Optimistic Verifiable Training by Controlling Hardware Nondeterminism](https://arxiv.org/pdf/2403.09603.pdf) by [Megha Srivastava](https://cs.stanford.edu/~megha), [Simran Arora](https://arorasimran.com/), and [Dan Boneh](https://crypto.stanford.edu/~dabo/). In this work, we show how to eliminate hardware nondeterminism (i.e. achieve identical weights after training on two different GPU types) in order to design a verification scheme for 3rd party auditing of model training services. For any questions, please contact megha@cs.stanford.edu! 

If you find this repository useful, please cite:

```
@inproceedings{srivastava2024verifiable,
    title = "Optimistic Verifiable Training by Controlling Hardware Nondeterminism",
    author = "Srivastava, Megha and Arora, Simran and Boneh, Dan",
    booktitle = "arxiv",
    year = "2024",
}
```

## Dependencies & First Steps

## Adding Model Checkpoints into Merkle Tree

## Overview
